# -*- coding: utf-8 -*-
"""data_fetcher.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/111Lm4elvt_3PKLSaa0h_jKcS0no2-e9h
"""

import requests
from PIL import Image
from io import BytesIO

MAPBOX_TOKEN = "pk.eyJ1IjoiYXJ1bjE1MDkiLCJhIjoiY21rMjhiemMwMGVyODNlcTRpamp5MG03ZiJ9.mHlkIkISkbtEbfK3_DWhEQ"

lat, lon = 47.5112, -122.257
url = f"https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/{lon},{lat},18/224x224"
params = {"access_token": MAPBOX_TOKEN}

response = requests.get(url, params=params)
print("Status:", response.status_code)

img = Image.open(BytesIO(response.content))
img

print("Train rows:", len(train_coords))
print("Test rows :", len(test_coords))

import os

os.makedirs("images/train", exist_ok=True)
os.makedirs("images/test", exist_ok=True)

print("Folders created")

print(os.listdir("images"))

import requests
from tqdm import tqdm
import time

MAPBOX_TOKEN = "pk.eyJ1IjoiYXJ1bjE1MDkiLCJhIjoiY21rMjhiemMwMGVyODNlcTRpamp5MG03ZiJ9.mHlkIkISkbtEbfK3_DWhEQ"

def download_images(df, save_dir):
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        lat, lon = row["lat"], row["long"]

        url = f"https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/{lon},{lat},18/224x224"
        params = {"access_token": MAPBOX_TOKEN}

        try:
            r = requests.get(url, params=params)
            if r.status_code == 200:
                with open(f"{save_dir}/{idx}.png", "wb") as f:
                    f.write(r.content)
            else:
                print(f"Failed to download image for index {idx} with status code {r.status_code}")
        except requests.exceptions.ConnectionError as e:
            print(f"Connection error for index {idx}: {e}")
            # You might want to implement a retry mechanism here or break/continue
        except Exception as e:
            print(f"An unexpected error occurred for index {idx}: {e}")

        # Add a small delay to avoid hitting rate limits
        time.sleep(0.1) # Sleep for 100 milliseconds

download_images(train_coords.iloc[:10], "images/train")
download_images(test_coords.iloc[:10], "images/test")

print("Train images:", os.listdir("images/train"))
print("Test images :", os.listdir("images/test"))

# download_images(train_coords, "images/train")
# download_images(test_coords, "images/test")

# Download a smaller subset for demonstration
download_images(train_coords.iloc[:50], "images/train")
download_images(test_coords.iloc[:50], "images/test")

import os

train_imgs = os.listdir("images/train")
test_imgs  = os.listdir("images/test")

print("Train images downloaded:", len(train_imgs))
print("Test images downloaded :", len(test_imgs))

# Download subset (recommended)
download_images(train_coords.iloc[:2000], "images/train")
download_images(test_coords.iloc[:500], "images/test")

!pip install torch torchvision

import os
import numpy as np
from PIL import Image
from tqdm import tqdm

import torch
import torch.nn as nn
from torchvision import models, transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

resnet = models.resnet18(pretrained=True)

# Remove the final classification layer
resnet = nn.Sequential(*list(resnet.children())[:-1])

resnet = resnet.to(device)
resnet.eval()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

def extract_embeddings(image_dir):
    embeddings = []

    image_files = sorted(os.listdir(image_dir), key=lambda x: int(x.split(".")[0]))

    with torch.no_grad():
        for img_name in tqdm(image_files):
            img_path = os.path.join(image_dir, img_name)
            img = Image.open(img_path).convert("RGB")
            img = transform(img).unsqueeze(0).to(device)

            feat = resnet(img)
            feat = feat.view(feat.size(0), -1)  # flatten
            embeddings.append(feat.cpu().numpy()[0])

    return np.array(embeddings)

train_img_embeddings = extract_embeddings("images/train")
print(train_img_embeddings.shape)

test_img_embeddings = extract_embeddings("images/test")
print(test_img_embeddings.shape)

np.save("train_img_embeddings.npy", train_img_embeddings)
np.save("test_img_embeddings.npy", test_img_embeddings)

import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import Ridge

# Tabular data
X_train_tab = np.load("X_train.npy")
X_val_tab   = np.load("X_val.npy")
X_test_tab  = np.load("X_test.npy")

y_train = np.load("y_train.npy")
y_val   = np.load("y_val.npy")

# Image embeddings
X_train_img = np.load("train_img_embeddings.npy")
X_test_img  = np.load("test_img_embeddings.npy")

n_train_imgs = X_train_img.shape[0]
n_test_imgs  = X_test_img.shape[0]

X_train_tab = X_train_tab[:n_train_imgs]
y_train     = y_train[:n_train_imgs]

X_test_tab  = X_test_tab[:n_test_imgs]

X_train_multi = np.hstack([X_train_tab, X_train_img])
X_val_multi   = np.hstack([X_val_tab[:len(X_train_img)], X_train_img])
X_test_multi  = np.hstack([X_test_tab, X_test_img])

print(X_train_multi.shape)

multi_model = Ridge(alpha=1.0)
multi_model.fit(X_train_multi, y_train)

y_val_aligned = y_val[:len(X_val_multi)]

from sklearn.metrics import mean_squared_error, mean_absolute_error

# Evaluate on TRAIN multimodal subset
y_train_pred_multi = multi_model.predict(X_train_multi)

rmse_multi = np.sqrt(mean_squared_error(y_train, y_train_pred_multi))
mae_multi  = mean_absolute_error(y_train, y_train_pred_multi)

print("MULTIMODAL MODEL PERFORMANCE (TRAIN SUBSET)")
print(f"RMSE: {rmse_multi:.4f}")
print(f"MAE : {mae_multi:.4f}")

